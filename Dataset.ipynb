{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434be170-0427-413a-ad77-f501cb924a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import srt\n",
    "import csv\n",
    "import re\n",
    "import asyncio\n",
    "import bisect\n",
    "import ffprobe3\n",
    "\n",
    "from ffmpeg import FFmpeg, FFmpegError\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from datetime import datetime\n",
    "from ffmpeg.asyncio import FFmpeg as AsyncFFmpeg\n",
    "from functools import partial\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fe9bf-12c0-4a12-aa5e-7956063c11db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ensure_paths():\n",
    "    global main_path, video_path, oped_path, subs_path, audio_path, clips_path\n",
    "    main_path = Path(\"X:\\ML\\Datasets\\koe\")\n",
    "    video_path = main_path / \"video\"\n",
    "    oped_path = main_path / \"oped\"\n",
    "    subs_path = main_path / \"subs\"\n",
    "\n",
    "    audio_path = main_path / \"generated\" / \"audio\"\n",
    "    clips_path = main_path / \"generated\" / \"clips\"\n",
    "    audio_path.mkdir(exist_ok=True, parents=True)\n",
    "    clips_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "ensure_paths()\n",
    "\n",
    "num_opeds = 370 #-1 = all\n",
    "\n",
    "videos = glob.glob(str(video_path) + \"/*.mkv\")\n",
    "opeds = glob.glob(str(oped_path) + \"/*.webm\")\n",
    "\n",
    "shuffle(opeds)\n",
    "opeds = opeds if num_opeds == -1 else opeds[:num_opeds]\n",
    "\n",
    "videos = videos + opeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2526b-cc1b-4862-b44f-6145e9329811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating WAV files...\")\n",
    "vids = tqdm(videos)\n",
    "for v in vids:\n",
    "    path = Path(v)\n",
    "    name = path.stem\n",
    "    vids.set_description(name)\n",
    "    audio_output = audio_path / (name + '.wav')\n",
    "    if audio_output.exists():\n",
    "        continue\n",
    "    \n",
    "    ffprobe_output = ffprobe3.probe(v)\n",
    "    audio_index = 0 #default to \n",
    "    for i in range(len(ffprobe_output.audio)):\n",
    "        s = ffprobe_output.audio[i]\n",
    "        if 'tags' not in s.parsed_json:\n",
    "            break\n",
    "        tags = s.parsed_json['tags']\n",
    "        if \"language\" not in tags:\n",
    "            break\n",
    "        if tags[\"language\"] == \"jpn\":\n",
    "            audio_index = i\n",
    "            break\n",
    "    \n",
    "    ffmpeg = (\n",
    "        FFmpeg()\n",
    "        .input(str(v))\n",
    "        .option(\"vn\")\n",
    "        .output(\n",
    "            audio_output,\n",
    "            map=[\"0:a:\" + str(audio_index)],\n",
    "            acodec=\"pcm_s16le\",\n",
    "            ar=16000,\n",
    "            ac=1,\n",
    "        )\n",
    "    )\n",
    "    try:\n",
    "        ffmpeg.execute()\n",
    "    except FFmpegError as exception:\n",
    "        print(\"- Message from ffmpeg:\", exception.message)\n",
    "        print(\"- Arguments to execute ffmpeg:\", \" \".join(exception.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5272e4f-d557-4679-ac7e-918ed88d3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamps = main_path / \"timestamps.csv\"\n",
    "\n",
    "def secs_to_timecode(secs):\n",
    "    hours, remainder = divmod(secs, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    str_time = '{:02}:{:02}:{:02.3f}'.format(int(hours), int(minutes), seconds)\n",
    "    return str_time\n",
    "\n",
    "def timecode_to_secs(timecode):\n",
    "    t = datetime.strptime(timecode, \"%H:%M:%S.%f\")\n",
    "    seconds = (t.second*1000000 + t.microsecond)/1000000\n",
    "    seconds += t.minute*60\n",
    "    seconds += t.hour*60*60\n",
    "    \n",
    "    #print(f'{timecode} -> {seconds}')\n",
    "    \n",
    "    return seconds\n",
    "\n",
    "#model informing \n",
    "time_span = 6\n",
    "time_steps = 30\n",
    "#model agnostic, (controls how many files in our dataset basically)\n",
    "time_shift = 6\n",
    "\n",
    "def get_time_codes(duration):\n",
    "    codes = []\n",
    "    mult = 1000\n",
    "    t_range = [x/mult for x in range(int(time_span*mult*.5), int(mult*(duration - time_span*.5)), int(time_shift*mult))]\n",
    "    for i in t_range:\n",
    "        start = i - time_span/2\n",
    "        codes.append(start)\n",
    "    return codes\n",
    "\n",
    "def parse_sub_file(subs_file):\n",
    "    with open(subs_file) as f:\n",
    "        lines = f.readlines()\n",
    "    subs = list(srt.parse(\"\\n\".join(lines)))\n",
    "    starts = []\n",
    "    stops = [] \n",
    "    for s in subs:\n",
    "        content = s.content\n",
    "        table = content.maketrans(\"<>（）}{\", \"()())(\") #Swap out alternative brackets for normal ones\n",
    "        content = content.translate(table)\n",
    "        content = re.sub(\"\\(.*?\\)\",\"\", content) #Get rid of all bracketed stuff\n",
    "        content = content.replace(\"♪\", \"\").replace(\"～\", \"\").replace(\"…\", \"\").strip()\n",
    "        if content:\n",
    "            starts.append(s.start.total_seconds())\n",
    "            stops.append(s.end.total_seconds())\n",
    "    return starts, stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a37f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "stamps = []\n",
    "with open(timestamps, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        stamps.append(row)\n",
    "\n",
    "timestamp_map = {}\n",
    "\n",
    "for v in videos:\n",
    "    video_path = Path(v)\n",
    "    if video_path.suffix == \".webm\": #OPED, region is just the runtime of the whole thing\n",
    "        timestamp_map[video_path.stem] = 0\n",
    "    else:\n",
    "        for row in stamps:\n",
    "            if row[0] == video_path.name:\n",
    "                timestamp_map[video_path.stem] = [timecode_to_secs(ts) for ts in row[1:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmentation(clip_start, clip_stop, segment_start, segment_stop):\n",
    "    label = [0, 0.0, 0.0] #[T/F, start, stop]\n",
    "    duration = clip_stop - clip_start\n",
    "    if clip_start >= segment_stop or clip_stop <= segment_start: #clip starts after the segment in question or clip stops before the segment starts\n",
    "        return label\n",
    "    else: #clip must have some section that is active\n",
    "        label[0] = 1\n",
    "        \n",
    "        # CLIP START FRACTS\n",
    "        if clip_start >= segment_start: #clip starts after or at the same time as the segment start\n",
    "            label[1] = 0.0\n",
    "        else: #clip starts before the segment starts\n",
    "            rel_start = (segment_start - clip_start)\n",
    "            fract_start = rel_start/duration\n",
    "            label[1] = round(fract_start, 4)\n",
    "    \n",
    "        # CLIP STOP FRACTS\n",
    "        if clip_stop > segment_stop: #clip continues either to the end or past the segment\n",
    "            rel_stop = (segment_stop - clip_start) #time of the stop relative to beginning of clip\n",
    "            fract_stop = rel_stop/duration #time of the stop as a fraction of the clip duration (should be between 0-1)\n",
    "            label[2] = round(fract_stop, 4)\n",
    "        else: #clip ends before or at the segment stop, IE the segment starts before the clip start and ends after the clip end\n",
    "            label[2] = 1.0\n",
    "\n",
    "    return label\n",
    "\n",
    "def clip(val, max_val, min_val):\n",
    "    return min(max(min_val, val), max_val)\n",
    "\n",
    "#This is only called for \n",
    "def generate_labels(file, start_time):\n",
    "    labels = [] #len = time_steps*catagories(4)\n",
    "    times = timestamp_map[file][0]\n",
    "    sub_starts, sub_stops = parse_sub_file(subs_path / Path(file + \".srt\"))\n",
    "    step_duration = time_span/time_steps\n",
    "    for step in range(time_steps):\n",
    "        time_step_start = start_time + step*step_duration #time at the current time step\n",
    "        time_step_stop = start_time + (step+1)*step_duration\n",
    "        \n",
    "        op_start, op_stop, ed_start, ed_stop = times\n",
    "        \n",
    "        op_seg = get_segmentation(time_step_start, time_step_stop, op_start, op_stop)\n",
    "        ed_seg = get_segmentation(time_step_start, time_step_stop, ed_start, ed_stop)\n",
    "        \n",
    "        #copy whichever, if any, is vtalid. Not need o train extra output, op vs ed can be determined by timecode\n",
    "        oped_seg = op_seg\n",
    "        if ed_seg[0]:\n",
    "            oped_seg = ed_seg \n",
    "        \n",
    "        #assuming subtitles don't overlap...\n",
    "        #Get sandwhiching indices of clip, check all subtitles between them\n",
    "        bound = partial(clip, max_val=(len(sub_starts) - 1), min_val=0)\n",
    "        bound_left = bound(bisect.bisect_left(sub_stops, time_step_start) - 1)#right-most sub_stop <= to the clip_start\n",
    "        bound_right = bound(bisect.bisect_right(sub_starts, time_step_stop) - 1)#left-most sub_start >= the clip_stop\n",
    "        \n",
    "        speech_segs = []\n",
    "        for i in range(bound_left, bound_right + 1):\n",
    "            sub_start = sub_starts[i]\n",
    "            sub_stop = sub_stops[i]\n",
    "            segs = get_segmentation(time_step_start, time_step_stop, sub_start, sub_stop)\n",
    "            speech_segs.append(segs)\n",
    "        \n",
    "        #If there are multiple overlapping subtitles for any reason, they will be merged into one segmentation since we are already at the predefined max segmentation\n",
    "        #merge them \n",
    "        speech_seg = [0, 0.0, 0.0]\n",
    "        min_start = 1.0\n",
    "        max_stop = 0.0\n",
    "        for segment in speech_segs:\n",
    "            if segment[0] == 1: #There is speech somewhere in this clip\n",
    "                speech_seg[0] = 1\n",
    "            if segment[1] < min_start:\n",
    "                min_start = segment[1]\n",
    "                speech_seg[1] = min_start\n",
    "            if segment[2] > max_stop:\n",
    "                max_stop = segment[2]\n",
    "                speech_seg[2] = max_stop\n",
    "                \n",
    "        #Dataset is based on subtitles, ignore speech segments when it is also OP or ED since those are lyrics\n",
    "        if oped_seg[0] and speech_seg[0]:\n",
    "            if speech_seg[1] >= oped_seg[1]: #speech starts after or at the same time as op\n",
    "                if oped_seg[2] >= speech_seg[1]: #op ends at the same time or after the speech tag, there is no room for independent speech\n",
    "                    speech_seg = [0, 0.0, 0.0]\n",
    "                else:   \n",
    "                    speech_seg[1] = oped_seg[2] #Start speech at the end point of the op seg\n",
    "            else: #speech starts before op segment begins\n",
    "                speech_seg[2] = oped_seg[1] #end the speech segment when the op begins\n",
    "         \n",
    "        # Row: Speech, Speech Start, Speech Stop,  OPED, OPED Start, OPED Stop\n",
    "        segments = speech_seg + oped_seg\n",
    "        labels.append(segments)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in timestamp_map.keys():\n",
    "    audio_file = audio_path / Path(x + \".wav\")\n",
    "    ffprobe_output = ffprobe3.probe(str(audio_file))\n",
    "\n",
    "    audio_stream = ffprobe_output.audio[0]\n",
    "    duration = audio_stream.duration_secs\n",
    "    timestamp_map[x] = (timestamp_map[x], duration)\n",
    "\n",
    "async def generate_clip(input_file, output_file, start_time, duration):\n",
    "    \n",
    "    ffmpeg = (\n",
    "        AsyncFFmpeg()\n",
    "        .input(str(input_file))\n",
    "        .option(\"vn\")\n",
    "        .output(\n",
    "            output_file,\n",
    "            ss=start_time,\n",
    "            t=duration\n",
    "        )\n",
    "    )\n",
    "    try:\n",
    "        await ffmpeg.execute()\n",
    "    except FFmpegError as exception:\n",
    "        print(\"- Message from ffmpeg:\", exception.message)\n",
    "        print(\"- Arguments to execute ffmpeg:\", \" \".join(exception.arguments))\n",
    "        \n",
    "sem = asyncio.Semaphore(24)\n",
    "\n",
    "async def safe_generate_clip(input_file, output_file, start_time, duration):\n",
    "    async with sem:\n",
    "        return await generate_clip(input_file, output_file, start_time, duration)\n",
    "\n",
    "ensure_paths()\n",
    "\n",
    "tasks = [] #run multiple at a time at most to not freeze everything\n",
    "labels = {}\n",
    "print('Generating Labels...')\n",
    "\n",
    "keys = tqdm(timestamp_map.keys())\n",
    "for x in keys:\n",
    "    oped_file = timestamp_map[x][0] == 0\n",
    "    audio_file = audio_path / Path(x + \".wav\")\n",
    "    subs_file = subs_path / Path(x + \".srt\")\n",
    "    \n",
    "    keys.set_description(str(audio_file.stem))\n",
    "    for start_time in get_time_codes(timestamp_map[x][1]):\n",
    "        output_name = (x + \"_\" + str(round(start_time, 2)) + \"_\" + str(duration) + '.wav')\n",
    "        \n",
    "        if oped_file:\n",
    "            segments = [[0, 0, 0, 1, 0.0, 1.0] for i in range(time_steps)]\n",
    "        else:\n",
    "            segments = generate_labels(x, start_time)\n",
    "        \n",
    "        labels[output_name] = segments\n",
    "        \n",
    "        input_file = audio_file\n",
    "        output_file = clips_path / output_name\n",
    "        \n",
    "        duration = time_span\n",
    "        if not output_file.exists():\n",
    "            tasks.append(asyncio.ensure_future(safe_generate_clip(input_file, output_file, start_time, duration)))\n",
    "print(\"Saving labels...\")\n",
    "\n",
    "with open(main_path / 'labels.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    writer.writerow(['File','Speech', 'Speech Start', 'Speech Stop', 'OPED', 'OPED Start', 'OPED Stop'])\n",
    "    for file_name in labels.keys():\n",
    "        for segment in labels[file_name]:\n",
    "            writer.writerow([str(clips_path / file_name)] + segment)\n",
    "\n",
    "print(\"Generating clips...\")\n",
    "await tqdm_asyncio.gather(*tasks)\n",
    "print(\"Done.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb335ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stat Collection\n",
    "# Compare OPED rows to dialogue rows, then we can use that to decide how many extra OP/EDs to include in the dataset\n",
    "\n",
    "dialogue_count = 0\n",
    "oped_count = 0\n",
    "with open(main_path / 'labels.csv', 'r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=\",\")\n",
    "    next(reader, None) #skip header\n",
    "    for row in reader:\n",
    "        dialogue_count += int(row[1])\n",
    "        oped_count += int(row[4])\n",
    "        \n",
    "print(f'Dialogue: {dialogue_count} - OPED {oped_count} -- {dialogue_count/oped_count}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3cc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
