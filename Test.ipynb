{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "import torch\n",
    "import ffprobe3\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from ffmpeg import FFmpeg, FFmpegError # type: ignore\n",
    "from IPython.display import Audio\n",
    "\n",
    "input_file = Path(\"X:/ML/Datasets/koe/video/Frieren_S01E01.mkv\")\n",
    "\n",
    "temp_dir = input_file.parent / \"temp\"\n",
    "temp_dir.mkdir(exist_ok=True)\n",
    "\n",
    "path = Path(input_file)\n",
    "name = path.stem\n",
    "\n",
    "outputs_dir = path.parent / \"outputs\"\n",
    "outputs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "output_file = outputs_dir / (name + \"_condensed.wav\")\n",
    "output_file_all = outputs_dir / (name + \"_condensed_all.wav\")\n",
    "output_op = outputs_dir / (name + \"_op.wav\")\n",
    "output_ed = outputs_dir / (name + \"_ed.wav\")\n",
    "audio_file = temp_dir / (name + '.wav')\n",
    "\n",
    "if not audio_file.exists():\n",
    "    \n",
    "    ffprobe_output = ffprobe3.probe(str(path))    \n",
    "\n",
    "    audio_index = 0 #default to \n",
    "    for i in range(len(ffprobe_output.audio)):\n",
    "        s = ffprobe_output.audio[i]\n",
    "        tags = s.parsed_json['tags']\n",
    "        if \"language\" not in tags:\n",
    "            break\n",
    "        if tags[\"language\"] == \"jpn\":\n",
    "            audio_index = i\n",
    "            break\n",
    "\n",
    "    ffmpeg = (\n",
    "        FFmpeg()\n",
    "        .input(str(path))\n",
    "        .option(\"vn\")\n",
    "        .output(\n",
    "            temp_dir / (name + '.wav'),\n",
    "            map=[\"0:a:\" + str(audio_index)],\n",
    "            acodec=\"pcm_s16le\",\n",
    "        )\n",
    "    )\n",
    "    try:\n",
    "        ffmpeg.execute()\n",
    "    except FFmpegError as exception:\n",
    "        print(\"- Message from ffmpeg:\", exception.message)\n",
    "        print(\"- Arguments to execute ffmpeg:\", \" \".join(exception.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") #test cpu inference\n",
    "#torch.set_num_threads(16)\n",
    "\n",
    "model_path = Path(\"H:/Documents/Dev/ML/Koe.moe/checkpoints/latest.pt\")\n",
    "\n",
    "model = torch.load(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "bs = 128 if device.type != \"cpu\" else 32\n",
    "sr = 16000\n",
    "len_sec = 6\n",
    "\n",
    "len_samples = len_sec*sr\n",
    "\n",
    "o,o_sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "y = librosa.resample(o, orig_sr=o_sr, target_sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pad end to get non-fractional number of clips\n",
    "num_clips = int(math.ceil(y.shape[0]/len_samples))\n",
    "missing_samples = num_clips*len_samples - y.shape[0]\n",
    "\n",
    "zeros = np.zeros(missing_samples)\n",
    "y = np.append(y, zeros, axis=0)\n",
    "\n",
    "#reshape into clip length\n",
    "_y = y.reshape((num_clips, len_samples))\n",
    "\n",
    "#generate inputs\n",
    "inputs = []\n",
    "for i in range(_y.shape[0]):\n",
    "    melspec = librosa.feature.melspectrogram(y=_y[i], sr=sr, hop_length=160)\n",
    "    melspec = librosa.power_to_db(melspec, ref=np.max)\n",
    "    inputs.append(melspec)\n",
    "\n",
    "inputs = np.array(inputs).astype(np.float32)\n",
    "inputs = torch.from_numpy(np.array([inputs])).to(device)\n",
    "inputs = inputs.permute(1, 0, 2, 3)\n",
    "\n",
    "batches = int(math.ceil(inputs.shape[0]/bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.94it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting inference...\")\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(range(batches)):\n",
    "        start = b*bs\n",
    "        end = (b+1)*bs if b != (batches - 1) else inputs.shape[0]\n",
    "        batch = inputs[start:end]\n",
    "        #print(\"Batch: \" + str(b+1))\n",
    "        outputs += model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848.0030308663845#0.02191860747213165\n",
      "848.2018696742132#0.022941394553830225\n",
      "848.4031820695848#0.02453334992751479\n",
      "848.6022010818124#0.02621885286644101\n",
      "848.8020034944639#0.027056149486452342\n",
      "849.0017756106332#0.027303261775523426\n",
      "849.2036617122591#0.027749315618226925\n",
      "849.402867500484#0.028879483261456094\n",
      "849.6024612441659#0.028879483261456094\n",
      "849.8031638208777#0.029044715904941162\n",
      "850.0038693111389#0.02894144874686996\n",
      "850.2013769302517#0.028868486701200406\n",
      "850.4024803942069#0.028868486701200406\n",
      "850.6021693335846#0.02853619595989585\n",
      "850.801161056105#0.02853619595989585\n",
      "851.0013051761314#0.028471725589285294\n",
      "851.2018121872097#0.028435110642264286\n",
      "851.4010514161549#0.028435110642264286\n",
      "851.6018632721156#0.028435110642264286\n",
      "851.8041084144264#0.028435110642264286\n",
      "852.0008584196679#0.028435110642264286\n",
      "852.2006638792343#0.028435110642264286\n",
      "852.401030175481#0.028435110642264286\n",
      "852.6009490737691#0.028435110642264286\n",
      "852.8007239813451#0.028435110642264286\n",
      "853.0010652858764#0.028435110642264286\n",
      "853.2009547127411#0.028435110642264286\n",
      "853.4008178771473#0.028435110642264286\n",
      "853.60124538932#0.028435110642264286\n",
      "853.8007670885884#0.028435110642264286\n",
      "854.0013622376136#0.028435110642264286\n",
      "854.2008381380699#0.028435110642264286\n",
      "854.4014899973757#0.028435110642264286\n",
      "854.6008832927794#0.028435110642264286\n",
      "854.8007232655306#0.028435110642264286\n",
      "855.0007295106072#0.028435110642264286\n",
      "855.2013634783216#0.028435110642264286\n",
      "855.4010578585788#0.028435110642264286\n",
      "855.6009408881888#0.028435110642264286\n",
      "855.8011685309#0.028435110642264286\n",
      "856.0013671747408#0.028435110642264286\n",
      "856.2004777658731#0.028435110642264286\n",
      "856.40095647946#0.028435110642264286\n",
      "856.6008390882052#0.028423922695219518\n",
      "856.8004159733188#0.028423922695219518\n",
      "857.0004522548522#0.028423922695219518\n",
      "857.2004823046736#0.028423922695219518\n",
      "857.4003260063706#0.028423922695219518\n",
      "857.6008817338385#0.028423922695219518\n",
      "857.8011577494442#0.028423922695219518\n",
      "858.0022197086364#0.028423922695219518\n",
      "858.201457818225#0.02840378526598215\n",
      "858.4020303616301#0.0266147934521238\n",
      "858.6017894029617#0.025298745868106685\n",
      "858.8012763713486#0.024121467582881452\n",
      "859.0016026247292#0.021611456697185834\n",
      "1489.6017194153742#0.022638250266512235\n",
      "1489.8014297824352#0.025544239766895772\n",
      "1490.0017994472757#0.028053496095041434\n",
      "1490.201208750345#0.029568680189549924\n",
      "1490.4027855439112#0.031362446335454784\n",
      "1490.6013929153792#0.03368349764496088\n",
      "1490.8016954062507#0.03503167970726887\n",
      "1491.0013317882083#0.03686083691815535\n",
      "1491.2034929782153#0.039186806169648966\n",
      "1491.4028688311578#0.04182230525960525\n",
      "1491.6021396851168#0.04360426589846611\n",
      "1491.802519553341#0.04626208400974671\n",
      "1492.0031826652587#0.04951578713953495\n",
      "1492.2014739380218#0.051200280773142974\n",
      "1492.4018039876596#0.053289009258151054\n",
      "1492.6015817942098#0.05528753539547324\n",
      "1492.8007869069465#0.05730599698921045\n",
      "1493.000704470789#0.0589930538708965\n",
      "1493.2009732922538#0.0603181308756272\n",
      "1493.4008358543738#0.0606351662427187\n",
      "1493.60152732227#0.061013798043131826\n",
      "1493.802632671222#0.061902604376276336\n",
      "1494.0007758236025#0.061902604376276336\n",
      "1494.200400016643#0.061902604376276336\n",
      "1494.4005104494747#0.061902604376276336\n",
      "1494.6003956419881#0.061902604376276336\n",
      "1494.8003512146418#0.061902604376276336\n",
      "1495.00054416731#0.061902604376276336\n",
      "1495.200276127085#0.061902604376276336\n",
      "1495.4004594962578#0.061902604376276336\n",
      "1495.600376313785#0.061902604376276336\n",
      "1495.8004056490026#0.061902604376276336\n",
      "1496.0004768236074#0.061902604376276336\n",
      "1496.2004327509087#0.061902604376276336\n",
      "1496.4007881745697#0.061902604376276336\n",
      "1496.6004719546065#0.061902604376276336\n",
      "1496.800435064407#0.061902604376276336\n",
      "1497.0006606062875#0.061902604376276336\n",
      "1497.2009647853672#0.061902604376276336\n",
      "1497.400787733309#0.061902604376276336\n",
      "1497.6007251758595#0.061902604376276336\n",
      "1497.800748239411#0.061902604376276336\n",
      "1498.0009423728102#0.061902604376276336\n",
      "1498.2003486000467#0.061902604376276336\n",
      "1498.4007773629855#0.06194910444319248\n",
      "1498.6005795123988#0.06194910444319248\n",
      "1498.8004228490404#0.06194910444319248\n",
      "1499.0002272418#0.06194910444319248\n",
      "1499.2004460474477#0.06194910444319248\n",
      "1499.400308409729#0.06194910444319248\n",
      "1499.6005506787915#0.06194910444319248\n",
      "1499.8008748286404#0.06194910444319248\n",
      "1500.00070951269#0.06194910444319248\n",
      "1500.200361438375#0.059971244012316065\n",
      "1500.40047687646#0.057494869579871495\n",
      "1500.6003475289094#0.054820162057876584\n",
      "1500.8002707433654#0.05225168019533157\n",
      "1501.000387352542#0.04878481365740299\n",
      "1501.2002205535537#0.04600570164620876\n",
      "1501.400346306106#0.04396829213947058\n",
      "1501.6003216882236#0.04214103370904922\n",
      "1501.8003044489305#0.039310854176680246\n",
      "1502.0004669683053#0.03640486467629671\n",
      "1502.2002994891955#0.03389560834815105\n",
      "1502.4007232459728#0.032380424253642556\n",
      "1502.6003245810512#0.0305866581077377\n",
      "1502.8003013275563#0.0282656067982316\n",
      "1503.0004599321169#0.02691742473592361\n",
      "1503.2008663370275#0.02508826752503713\n",
      "1503.4007838436403#0.022762298273543518\n",
      "1503.6004968255293#0.020126799183587233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def samples_to_t(samples):\n",
    "    return samples/sr\n",
    "\n",
    "class LabelData:\n",
    "    def __init__(self, name, threshold, padding, moving_avg=False, moving_avg_n=2, relative_to=-1, verbose=False):\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self.padding = padding\n",
    "        self.moving_avg = moving_avg\n",
    "        self.moving_avg_n = moving_avg_n\n",
    "        self.relative_to = relative_to\n",
    "        self.verbose = verbose\n",
    "        self.events = []\n",
    "\n",
    "events = {\"Speech\": [], \"OPED\": []}\n",
    "\n",
    "classes = int(outputs[0].shape[1] / 3)\n",
    "\n",
    "samples_per_segment = len_samples/outputs[0].shape[0]\n",
    "\n",
    "class_map = { #.475 2747\n",
    "    0: LabelData(\"Speech\", 0.455, [.7, .9], moving_avg=False, verbose=False),\n",
    "    1: LabelData(\"OPED\", .02, [.3, .3], moving_avg=True, relative_to=0, verbose=True)\n",
    "}\n",
    "\n",
    "for c in range(classes):\n",
    "    label_class = class_map[c]\n",
    "    \n",
    "    moving_avg_terms = int(label_class.moving_avg_n*outputs[0].shape[0])\n",
    "    last_n = []\n",
    "    \n",
    "    total_correct = 0\n",
    "    for i in range(len(outputs)):\n",
    "        clip = outputs[i]\n",
    "        clip_sample_offset = i*clip.shape[0]*samples_per_segment\n",
    "        for time_step in range(clip.shape[0]):\n",
    "            step_start_samples = clip_sample_offset + samples_per_segment*time_step\n",
    "            valid = clip[time_step][0 + c*3].item()\n",
    "            \n",
    "            if label_class.relative_to > -1:\n",
    "                valid = max(0, (valid - clip[time_step][label_class.relative_to*3].item()))\n",
    "                \n",
    "            #moving average\n",
    "            if label_class.moving_avg:\n",
    "                if len(last_n) == moving_avg_terms:\n",
    "                    new_valid = (valid + sum(last_n))/moving_avg_terms\n",
    "                    for j in range(0, moving_avg_terms - 1):\n",
    "                        last_n[j] = last_n[j+1]\n",
    "                    last_n[-1] = valid\n",
    "                    valid = new_valid\n",
    "                else:\n",
    "                    last_n.append(valid)\n",
    "            \n",
    "            start = clip[time_step][1 + c*3].item()\n",
    "            stop = clip[time_step][2 + c*3].item()\n",
    "            \n",
    "            if valid >= label_class.threshold and start < stop:\n",
    "                start_time = step_start_samples + start*samples_per_segment\n",
    "                stop_time = step_start_samples + stop*samples_per_segment\n",
    "                label_class.events.append((valid, start_time, stop_time))\n",
    "                if label_class.verbose: print(f'{samples_to_t(start_time)}#{valid}')\n",
    "\n",
    "for idx, label_class in class_map.items():\n",
    "    for i in range(0, len(label_class.events)):\n",
    "        curr = label_class.events[i]\n",
    "        new_start = max(0, curr[1] - sr*label_class.padding[0]) \n",
    "        new_stop = min(y.shape[0] - 1, curr[1] + sr*label_class.padding[1])\n",
    "        label_class.events[i] = (curr[0], new_start, new_stop)\n",
    "        \n",
    "#Otherwise the subsequent clip concatentation is very slow\n",
    "smoothing = .1\n",
    "for idx, label_class in class_map.items():\n",
    "    smoothed_events = []\n",
    "    previous_pointer = 0\n",
    "    for i in range(1, len(label_class.events)):\n",
    "        prev = label_class.events[previous_pointer]\n",
    "        curr = label_class.events[i]\n",
    "        if curr[1] - prev[2] <= smoothing:\n",
    "            label_class.events[i] = (curr[0], prev[1], curr[2])\n",
    "            label_class.events[previous_pointer] = None\n",
    "        previous_pointer = i\n",
    "    label_class.events = list(filter(lambda x: x, label_class.events))\n",
    "\n",
    "\n",
    "sr_correction = o_sr/sr\n",
    "all_speech = np.array([])\n",
    "speech_class = class_map[0]\n",
    "for i in range(0, len(speech_class.events)):\n",
    "        clip_start = speech_class.events[i][1]*sr_correction\n",
    "        clip_stop = speech_class.events[i][2]*sr_correction\n",
    "        clip = o[int(clip_start):int(clip_stop)]\n",
    "        all_speech = np.concatenate((all_speech, clip))\n",
    "\n",
    "sf.write(output_file, all_speech, o_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = np.array([])\n",
    "ed = np.array([])\n",
    "oped_class = class_map[1]\n",
    "for i in range(0, len(oped_class.events)):\n",
    "        clip_start = oped_class.events[i][1]*sr_correction\n",
    "        clip_stop = oped_class.events[i][2]*sr_correction\n",
    "        clip = o[int(clip_start):int(clip_stop)]\n",
    "        \n",
    "        if clip_start >= (y.shape[0]/2):\n",
    "            ed = np.concatenate((ed, clip))\n",
    "        else:\n",
    "            op = np.concatenate((op, clip))\n",
    "\n",
    "all = np.array([])\n",
    "\n",
    "if op.shape[0] > 0:\n",
    "    all = np.concatenate((all, op))\n",
    "    sf.write(output_op, op, o_sr)\n",
    "    \n",
    "all = np.concatenate((all, all_speech))\n",
    "    \n",
    "if ed.shape[0] > 0:\n",
    "    all = np.concatenate((all, ed))\n",
    "    sf.write(output_ed, ed, o_sr)\n",
    "    \n",
    "sf.write(output_file_all, all, o_sr)\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastxtend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
